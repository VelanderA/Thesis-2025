{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af13b802-591c-495f-8e7c-58fd4b1bd0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Anneth\\\\Documents\\\\GitHub\\\\Thesis-2025\\\\extend_experiment'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014ac434-7243-4af2-ad34-96cec2e0d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0       id  \\\n",
      "0                0   627762   \n",
      "1                1  5892815   \n",
      "2                2   416437   \n",
      "3                3  5137126   \n",
      "4                4   855753   \n",
      "...            ...      ...   \n",
      "447995      447995  1018736   \n",
      "447996      447996   340016   \n",
      "447997      447997   919629   \n",
      "447998      447998  5165492   \n",
      "447999      447999  4984105   \n",
      "\n",
      "                                             comment_text  split  \\\n",
      "0       OH yes - Were those evil Christian Missionarie...   test   \n",
      "1       Why is this black racist crap still on the G&M...    val   \n",
      "2                              even up here.......BLACKS!  train   \n",
      "3       Blame men.  There's always an excuse to blame ...  train   \n",
      "4       And the woman exposing herself saying grab thi...    val   \n",
      "...                                                   ...    ...   \n",
      "447995  Another man shamming article. If white men did...  train   \n",
      "447996  \"no matter what is put in front of you regardi...  train   \n",
      "447997  The Democrat party aided and abetted by it's M...   test   \n",
      "447998  I just don't find her a very good representati...  train   \n",
      "447999  You know the Trump fanatics are trolling the G...  train   \n",
      "\n",
      "                         created_date  publication_id  parent_id  article_id  \\\n",
      "0       2016-11-26 15:56:03.862109+00              13   627198.0      152737   \n",
      "1       2017-09-03 23:20:08.226613+00              54        NaN      373428   \n",
      "2       2016-08-04 16:48:07.175252+00              21        NaN      143025   \n",
      "3       2017-04-15 19:00:45.032674+00              54  5136907.0      327125   \n",
      "4       2017-01-18 01:50:57.478867+00              13   849081.0      162008   \n",
      "...                               ...             ...        ...         ...   \n",
      "447995  2017-02-20 07:20:49.964620+00              54        NaN      169202   \n",
      "447996  2016-06-06 06:43:04.780968+00              21   339965.0      137961   \n",
      "447997  2017-01-30 02:44:29.168863+00              54        NaN      164845   \n",
      "447998  2017-04-22 18:42:02.442987+00              54        NaN      328877   \n",
      "447999  2017-03-10 00:55:35.369198+00              54   807615.0      156960   \n",
      "\n",
      "          rating  funny  ...  asian_latino_etc  disability_any  identity_any  \\\n",
      "0       approved      0  ...                 0               0             1   \n",
      "1       rejected      0  ...                 0               0             1   \n",
      "2       rejected      0  ...                 0               0             1   \n",
      "3       rejected      0  ...                 0               0             1   \n",
      "4       rejected      0  ...                 0               0             1   \n",
      "...          ...    ...  ...               ...             ...           ...   \n",
      "447995  approved      0  ...                 0               0             1   \n",
      "447996  approved      0  ...                 0               0             1   \n",
      "447997  rejected      0  ...                 0               0             0   \n",
      "447998  approved      1  ...                 0               0             1   \n",
      "447999  approved      1  ...                 0               0             1   \n",
      "\n",
      "        num_identities  more_than_one_identity  na_gender  na_orientation  \\\n",
      "0                  1.0                   False          1               1   \n",
      "1                  2.0                    True          1               1   \n",
      "2                  1.0                   False          1               1   \n",
      "3                  2.0                    True          0               1   \n",
      "4                  1.0                   False          0               1   \n",
      "...                ...                     ...        ...             ...   \n",
      "447995             2.0                    True          0               1   \n",
      "447996             2.0                    True          0               1   \n",
      "447997             0.0                   False          1               1   \n",
      "447998             1.0                   False          0               1   \n",
      "447999             1.0                   False          1               1   \n",
      "\n",
      "        na_religion  na_race  na_disability  \n",
      "0                 0        1              1  \n",
      "1                 1        0              1  \n",
      "2                 1        0              1  \n",
      "3                 1        1              1  \n",
      "4                 1        1              1  \n",
      "...             ...      ...            ...  \n",
      "447995            1        0              1  \n",
      "447996            1        1              1  \n",
      "447997            1        1              1  \n",
      "447998            1        1              1  \n",
      "447999            0        1              1  \n",
      "\n",
      "[448000 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"./data/all_data_with_identities.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa6f29e-6151-4b72-aff3-2d8981740ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269038\n"
     ]
    }
   ],
   "source": [
    "\"\"\"filter data to generate two new vectors\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"./data/all_data_with_identities.csv\")\n",
    "df = df[df[\"split\"] == \"train\"]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46eac8b9-4758-4a43-83db-cd05c9c00b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All identity and toxicity columns to consider\n",
    "all_bias_cols = [\n",
    "    'funny', 'wow', 'sad', 'likes', 'disagree', 'toxicity', 'severe_toxicity',\n",
    "    'obscene', 'sexual_explicit', 'identity_attack', 'insult', 'threat',\n",
    "    'male', 'female', 'transgender', 'other_gender', 'heterosexual',\n",
    "    'homosexual_gay_or_lesbian', 'bisexual', 'other_sexual_orientation',\n",
    "    'christian', 'jewish', 'muslim', 'hindu', 'buddhist', 'atheist',\n",
    "    'other_religion', 'black', 'white', 'asian', 'latino',\n",
    "    'other_race_or_ethnicity', 'physical_disability',\n",
    "    'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
    "    'other_disability', 'identity_annotator_count', 'toxicity_annotator_count',\n",
    "    'LGBTQ', 'other_religions', 'asian_latino_etc', 'disability_any',\n",
    "    'identity_any', 'num_identities', 'more_than_one_identity',\n",
    "    'na_gender', 'na_orientation', 'na_religion', 'na_race', 'na_disability'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bcebc4-a95c-4088-bc40-b05f6350a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered rows: 19703\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'female' is not 0.0 and 'other_gender' is 0.0\n",
    "filtered_df_female = df[(df['female'] != 0.0) & (df['male'] == 0.0) & (df['other_gender'] == 0.0) & (df['disagree'] == 0.0) & (df['other_sexual_orientation'] == 0.0) & (df['transgender'] == 0.0)& (df['other_gender'] == 0.0)]\n",
    "\n",
    "# Output the number of filtered rows\n",
    "print(f\"Filtered rows: {len(filtered_df_female)}\")\n",
    "\n",
    "# Optionally, save the filtered dataset\n",
    "filtered_df_female[['comment_text']].to_csv(\"filtered_female_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538d55ea-730f-4f4d-bdfc-05667a37c015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered rows: 7464\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'female' is not 0.0 and 'other_gender' is 0.0\n",
    "filtered_df_black = df[(df['black'] != 0.0) & (df['white'] == 0.0)] #& (df['asian'] == 0.0) & (df['disagree'] == 0.0) & (df['latino'] == 0.0) & (df['other_race_or_ethnicity'] == 0.0)]\n",
    "\n",
    "# Output the number of filtered rows\n",
    "print(f\"Filtered rows: {len(filtered_df_black)}\")\n",
    "\n",
    "# Optionally, save the filtered dataset\n",
    "filtered_df_black[['comment_text']].to_csv(\"filtered_black_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a9f0e2-18ad-4f61-ba2d-0c2eecd0836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample size for female: 2000\n",
      "Random sample size for black: 2000\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 5000 rows for 'female' biased dataset\n",
    "random_female_sample = filtered_df_female.sample(n=2000, random_state=42)\n",
    "\n",
    "# Randomly select 5000 rows for 'black' biased dataset\n",
    "random_black_sample = filtered_df_black.sample(n=2000, random_state=42)\n",
    "\n",
    "# Save the random samples to CSV files\n",
    "random_female_sample[['comment_text']].to_csv(\"random_female_sample.csv\", index=False)\n",
    "random_black_sample[['comment_text']].to_csv(\"random_black_sample.csv\", index=False)\n",
    "\n",
    "# Output the size of the random samples\n",
    "print(f\"Random sample size for female: {len(random_female_sample)}\")\n",
    "print(f\"Random sample size for black: {len(random_black_sample)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
